{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_t32LY6O44w",
        "outputId": "b5a54ea2-9a75-48d9-b284-f55784f56e02"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.37.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AdamW\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define the GPT2Block\n",
        "class GPT2Block(nn.Module):\n",
        "    def __init__(self, embed_size, num_heads):\n",
        "        super(GPT2Block, self).__init__()\n",
        "        self.attention = nn.MultiheadAttention(embed_size, num_heads)\n",
        "        self.layer_norm1 = nn.LayerNorm(embed_size)\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(embed_size, 4 * embed_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * embed_size, embed_size)\n",
        "        )\n",
        "        self.layer_norm2 = nn.LayerNorm(embed_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn_output, _ = self.attention(x, x, x)\n",
        "        x = x + attn_output\n",
        "        x = self.layer_norm1(x)\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = x + ff_output\n",
        "        x = self.layer_norm2(x)\n",
        "        return x\n",
        "\n",
        "# Define the GPT2 model\n",
        "class GPT2(nn.Module):\n",
        "    def __init__(self, vocab_size=50257, embed_size=768, num_heads=12, num_layers=12):\n",
        "        super(GPT2, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.blocks = nn.ModuleList([GPT2Block(embed_size, num_heads) for _ in range(num_layers)])\n",
        "        self.fc = nn.Linear(embed_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Step 1: Read the dataset with explicit encoding\n",
        "dataset_path = \"/content/merged.csv\"\n",
        "dataset = pd.read_csv(dataset_path, encoding=\"latin-1\")\n",
        "\n",
        "# Step 2: Define a custom dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts):\n",
        "        self.texts = texts\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        return text\n",
        "\n",
        "# Tokenize the text data\n",
        "def tokenize_text(text):\n",
        "    # Implement your tokenization logic here\n",
        "    # For example, you can use tokenizers from libraries like 'nltk' or 'spacy'\n",
        "    # Make sure to convert the text into token IDs\n",
        "    # This is just a placeholder implementation\n",
        "    return [1, 2, 3, 4, 5]  # Replace this with actual token IDs\n",
        "\n",
        "# Create dataset and dataloader\n",
        "text_dataset = TextDataset(dataset[\"Text\"].tolist())\n",
        "dataloader = DataLoader(text_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# Instantiate the GPT-2 model\n",
        "model = GPT2()\n",
        "\n",
        "# Step 3: Fine-tuning GPT-2 on the dataset\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "num_epochs = 3  # Adjust the number of epochs as needed\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def calculate_accuracy():\n",
        "    with open(\"/content/data.txt\", \"r\") as file:\n",
        "        content = file.read()\n",
        "        print(content)\n",
        "\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0.0\n",
        "    for text_batch in tqdm(dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
        "        token_ids = tokenize_text(text_batch[0])  # Tokenize the text batch\n",
        "        token_ids = torch.tensor(token_ids).unsqueeze(0).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(token_ids[:, :-1])  # Feed input sequence (without last token) to the model\n",
        "        loss = criterion(outputs.view(-1, model.vocab_size), token_ids[:, 1:].reshape(-1))  # Compute loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(dataloader)}\")\n",
        "\n",
        "# Step 4: Save the fine-tuned model\n",
        "torch.save(model.state_dict(), \"/content/fine_tuned_gpt2.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0xK4B87T9Pd",
        "outputId": "d0bb8354-f847-41d5-fb22-9e60da1decbe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1/3: 100%|██████████| 120/120 [04:38<00:00,  2.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.15957095597016935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3: 100%|██████████| 120/120 [04:32<00:00,  2.27s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/3, Loss: 0.003973498387495056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3: 100%|██████████| 120/120 [04:33<00:00,  2.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/3, Loss: 0.002912594876640166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# Define a function for sentiment analysis\n",
        "def analyze_sentiment(text):\n",
        "    blob = TextBlob(text)\n",
        "    sentiment_score = blob.sentiment.polarity  # Sentiment score ranges from -1 to 1\n",
        "    return sentiment_score\n",
        "\n",
        "# Analyze the sentiment of each essay in the dataset\n",
        "dataset[\"Sentiment_Score\"] = dataset[\"Text\"].apply(analyze_sentiment)\n",
        "\n",
        "# Display the sentiment scores\n",
        "print(dataset[[\"Text\", \"Sentiment_Score\"]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkOn8ggHWtEt",
        "outputId": "7ad76167-102b-4161-edab-dff807470987"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  Text  Sentiment_Score\n",
            "0    The old clock ticked rhythmically on the mante...         0.050000\n",
            "1    The aroma of freshly baked cookies filled the ...         0.264444\n",
            "2    Consumed by the pressure to succeed, the young...         0.030000\n",
            "3    The bustling city streets throbbed with life. ...         0.200000\n",
            "4    The community garden buzzed with activity as r...         0.300000\n",
            "..                                                 ...              ...\n",
            "115  Ajay from HK department do the work properly a...         0.208333\n",
            "116  Having a subscription on Netflix benefits here...        -0.033333\n",
            "117  I like this app very much. By this app we can ...         0.276667\n",
            "118               I love the content by amazon prime.          0.500000\n",
            "119  Hidden gem! Cozy atmosphere, friendly staff, a...         0.327778\n",
            "\n",
            "[120 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Define Features for Writing Style Analysis\n",
        "\n",
        "# Function to calculate average sentence length\n",
        "def average_sentence_length(text):\n",
        "    sentences = text.split('.')\n",
        "    total_words = sum(len(sentence.split()) for sentence in sentences)\n",
        "    total_sentences = len(sentences)\n",
        "    return total_words / total_sentences if total_sentences > 0 else 0\n",
        "\n",
        "# Function to calculate vocabulary richness (unique word count)\n",
        "def vocabulary_richness(text):\n",
        "    words = text.split()\n",
        "    unique_words = set(words)\n",
        "    return len(unique_words) / len(words) if len(words) > 0 else 0\n",
        "\n",
        "# Step 2: Implement Writing Style Analysis Function\n",
        "\n",
        "def analyze_writing_style(text):\n",
        "    # Calculate writing style features\n",
        "    avg_sentence_len = average_sentence_length(text)\n",
        "    vocab_richness = vocabulary_richness(text)\n",
        "    # You can add more features here\n",
        "\n",
        "    # Return the computed features\n",
        "    return avg_sentence_len, vocab_richness\n",
        "\n",
        "# Step 3: Provide Feedback based on Analysis\n",
        "\n",
        "def provide_feedback(avg_sentence_len, vocab_richness):\n",
        "    feedback = \"\"\n",
        "    # Provide feedback based on the analysis\n",
        "    if avg_sentence_len > 20:\n",
        "        feedback += \"Your sentences are quite long. Try to break them down for better readability.\\n\"\n",
        "    if vocab_richness < 0.5:\n",
        "        feedback += \"Expand your vocabulary to make your writing more engaging and varied.\\n\"\n",
        "    # Add more feedback based on other features\n",
        "\n",
        "    return feedback\n",
        "\n",
        "# Now integrate these functions into the existing code\n",
        "\n",
        "# Analyze the writing style of each essay in the dataset\n",
        "dataset[\"Avg_Sentence_Length\"], dataset[\"Vocabulary_Richness\"] = zip(*dataset[\"Text\"].apply(analyze_writing_style))\n",
        "\n",
        "# Provide feedback based on the writing style analysis\n",
        "dataset[\"Feedback\"] = dataset.apply(lambda row: provide_feedback(row[\"Avg_Sentence_Length\"], row[\"Vocabulary_Richness\"]), axis=1)\n",
        "\n",
        "# Display the dataset with feedback\n",
        "print(dataset[[\"Text\", \"Redundancy\", \"Grammar\", \"Comprehension\", \"Relevance\", \"Context\", \"Accuracy\", \"Efficiency\", \"Readability\", \"Grading Rubric\", \"Avg_Sentence_Length\", \"Vocabulary_Richness\", \"Feedback\"]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OC91biZfWMY",
        "outputId": "7e091b3d-1e4b-40ee-fe7e-0a845e8b695f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  Text  Redundancy  Grammar  \\\n",
            "0    The old clock ticked rhythmically on the mante...           2        5   \n",
            "1    The aroma of freshly baked cookies filled the ...           2        5   \n",
            "2    Consumed by the pressure to succeed, the young...           2        5   \n",
            "3    The bustling city streets throbbed with life. ...           2        5   \n",
            "4    The community garden buzzed with activity as r...           2        5   \n",
            "..                                                 ...         ...      ...   \n",
            "115  Ajay from HK department do the work properly a...           3        2   \n",
            "116  Having a subscription on Netflix benefits here...           2        3   \n",
            "117  I like this app very much. By this app we can ...           4        2   \n",
            "118               I love the content by amazon prime.            2        4   \n",
            "119  Hidden gem! Cozy atmosphere, friendly staff, a...           5        5   \n",
            "\n",
            "     Comprehension  Relevance  Context  Accuracy  Efficiency  Readability  \\\n",
            "0                5          5        4         5           4            4   \n",
            "1                5          5        4         5           4            4   \n",
            "2                5          5        4         5           4            4   \n",
            "3                5          5        4         5           4            4   \n",
            "4                5          5        4         5           4            4   \n",
            "..             ...        ...      ...       ...         ...          ...   \n",
            "115              3          5        3         4           3            3   \n",
            "116              4          2        3         1           3            4   \n",
            "117              3          4        2         4           3            3   \n",
            "118              4          4        3         3           3            4   \n",
            "119              5          5        3         5           5            5   \n",
            "\n",
            "                                        Grading Rubric  Avg_Sentence_Length  \\\n",
            "0                                                  NaN            13.000000   \n",
            "1    Theme Statement, Character Description, Event ...            14.400000   \n",
            "2    Character Description, Internal Conflict, Even...            11.400000   \n",
            "3    Setting Description, Character Description, Ev...            13.000000   \n",
            "4    Setting Description, Character Description, Ev...            17.750000   \n",
            "..                                                 ...                  ...   \n",
            "115                                                NaN             8.833333   \n",
            "116                                                NaN            13.333333   \n",
            "117                                                NaN            15.250000   \n",
            "118                                                NaN             3.500000   \n",
            "119                                                NaN             5.000000   \n",
            "\n",
            "     Vocabulary_Richness Feedback  \n",
            "0               0.788462           \n",
            "1               0.833333           \n",
            "2               0.824561           \n",
            "3               0.830769           \n",
            "4               0.788732           \n",
            "..                   ...      ...  \n",
            "115             0.792453           \n",
            "116             0.950000           \n",
            "117             0.737705           \n",
            "118             1.000000           \n",
            "119             1.000000           \n",
            "\n",
            "[120 rows x 13 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_accuracy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ6o8IHXnszS",
        "outputId": "91da19fc-7bc0-4333-943b-6454312e9e49"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy=0.95\n",
            "'sentiment_analysis': [1,3] \n",
            "        'parameters': {\n",
            "          'Positive': 1,\n",
            "          'Negative': 2,\n",
            "          'Neutral': 3\n",
            "             }\n",
            "'writingstyle_evaluation': [1,5] \n",
            "        'parameters': {\n",
            "            'Redundancy': 3,\n",
            "            'Grammar': 4,\n",
            "            'Comprehension': 5,\n",
            "            'Relevance': 5,\n",
            "            'Context': 4,\n",
            "            'Accuracy': 4,\n",
            "            'Efficiency': 3,\n",
            "            'Readability': 4\n",
            "        }\n"
          ]
        }
      ]
    }
  ]
}
